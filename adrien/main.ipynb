{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7154322059096394540\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14284009452364380694\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15153353194510944333\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7708685108\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17084659989025928081\n",
      "physical_device_desc: \"device: 0, name: Graphics Device, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/sean/pench\")\n",
    "sys.path.append(\"/network/lustre/iss01/home/adrien.martel\")\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "# !git clone https://github.com/vlawhern/arl-eegmodels.git\n",
    "\n",
    "from eegmodels.EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
    "from myModels import dualLSTM, singleLSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.enable_eager_execution()\n",
    "from threading import Thread\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import math\n",
    "import threading\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras.backend as K\n",
    "# import keras\n",
    "# from tqdm.keras import TqdmCallback\n",
    "\n",
    "print(device_lib.list_local_devices()) # list of DeviceAttributes\n",
    "\n",
    "# %gui qt\n",
    "import numpy as np\n",
    "# import mne\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool, Queue\n",
    "import multiprocessing\n",
    "# tf.enable_eager_execution()\n",
    "from collections import deque\n",
    "\n",
    "from tensorflow.keras.backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(a, b, c):\n",
    "    # Generate the permutation index array.\n",
    "    permutation = np.random.permutation(a.shape[0])\n",
    "    # Shuffle the arrays by giving the permutation in the square brackets.\n",
    "    shuffled_a = a[permutation]\n",
    "    shuffled_b = b[permutation]\n",
    "    shuffled_c = c[permutation]\n",
    "    return shuffled_a, shuffled_b, shuffled_c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseFolder='one/'\n",
    "baseFolder='/network/lustre/iss01/home/adrien.martel/data/MW/'\n",
    "files=[f for f in os.listdir(baseFolder) if not f.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(file):\n",
    "    data=pickle.load(open(baseFolder+file, 'rb'))\n",
    "    \n",
    "    sfreq=512\n",
    "    features=[]\n",
    "    flipFeatures=[]\n",
    "    labels=[]\n",
    "    for i in range(numClasses):\n",
    "        for k in range(len(data[i])):\n",
    "            labels.append(i)\n",
    "            features.append(data[i][k])\n",
    "            flipFeatures.append([np.transpose(data[i][k])])\n",
    "    labels=np.array(labels)\n",
    "    features=np.array(features)\n",
    "    flipFeatures=np.array(flipFeatures)\n",
    "    labels, features, flipFeatures = randomize(labels, features, flipFeatures)\n",
    "    \n",
    "    labels = to_categorical(labels, num_classes=numClasses)\n",
    "    return [features, flipFeatures, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam=2560\n",
    "chans=62\n",
    "numClasses=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models  = [\n",
    "    [EEGNet(nb_classes=numClasses, Chans=chans, Samples=sam), True, 'EEGNet-V1'], \n",
    "    [ShallowConvNet(nb_classes=numClasses, Chans=chans, Samples =sam), True, 'ShallowConvNet-V1'], \n",
    "    [DeepConvNet(nb_classes=numClasses, Chans=chans, Samples=sam), True, 'DeepConvNet-V1'],\n",
    "    [singleLSTM(clas=numClasses, sam=sam, chans=chans), False, 'singleLSTM-V1'],\n",
    "    [dualLSTM(clas=numClasses, sam=sam, chans=chans), False, 'dualLSTM-V1'],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWork(n):\n",
    "    arc=inps[n][0]\n",
    "    file=inps[n][1]\n",
    "    features, flipFeatures, labels = createData(file)\n",
    "    if arc[1]:\n",
    "        train_X = np.array(flipFeatures[0:int(7*len(labels)/10)])\n",
    "        test_X = np.array(flipFeatures[int(7*len(labels)/10):-1])\n",
    "    else:\n",
    "        train_X = np.array(features[0:int(7*len(labels)/10)])\n",
    "        test_X = np.array(features[int(7*len(labels)/10):-1])\n",
    "    train_y = np.array(labels[0:int(7*len(labels)/10)])\n",
    "    test_y = np.array(labels[int(7*len(labels)/10):-1])\n",
    "    print(\"Putted\", file, out.empty())\n",
    "#     out.put([arc[0], train_X, test_X, train_y, test_y, file, arc[2]])\n",
    "    print(file, train_X.shape, test_X.shape, train_y.shape, test_y.shape)\n",
    "#     print(out.empty())\n",
    "    return [arc[0], train_X, test_X, train_y, test_y, file, arc[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably exists\n",
      "probably exists\n",
      "probably exists\n",
      "probably exists\n",
      "probably exists\n"
     ]
    }
   ],
   "source": [
    "inps=[]\n",
    "for model in models:\n",
    "    try:\n",
    "        os.mkdir(model[2])\n",
    "    except:\n",
    "        print(\"probably exists\")\n",
    "    for file in files:\n",
    "        inps.append([model, file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "out = manager.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# p = Pool(20)\n",
    "# master=p.map(createWork, list(range(2)))\n",
    "# master=p.map(createWork, list(range(len(inps))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus=4\n",
    "out.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out = Queue()\n",
    "# out.queue = queue.deque(master)\n",
    "[out.put(i) for i in list(range(len(inps)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doWork(i):\n",
    "#     i = args[0]\n",
    "#     out = args[1]\n",
    "#     i=1\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(i)\n",
    "    while not out.empty():\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, device_count = {'GPU': i}), graph=tf.Graph()) as sess:\n",
    "            K.set_session(sess)\n",
    "    #         dat=out.get()\n",
    "    #         print(\"not empty\")\n",
    "            n=out.get()\n",
    "            dat= createWork(n)\n",
    "            model=dat[0]\n",
    "            train_X=dat[1]\n",
    "            test_X=dat[2]\n",
    "            train_y=dat[3]\n",
    "            test_y=dat[4]\n",
    "            file=dat[5]\n",
    "            folder=dat[6]\n",
    "    #         print('processed')\n",
    "    #         sgd = keras.optimizers.SGD(learning_rate=0.015, momentum=0.0, nesterov=False)\n",
    "    #         adam = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "            print('Done getting data')\n",
    "    #         sgd = keras.optimizers.SGD()\n",
    "            adam = tf.train.AdamOptimizer(\n",
    "        learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, use_locking=False,\n",
    "        name='Adam'\n",
    "    )\n",
    "            print('Compiling model')\n",
    "    #         break\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "            # fit network\n",
    "\n",
    "            history = model.fit(train_X, train_y, epochs=10, batch_size=2, validation_data=(test_X, test_y), verbose=0, shuffle=True)\n",
    "            # plot history\n",
    "            print(history.history.keys())\n",
    "            pyplot.figure(figsize=(25,10), dpi=250)\n",
    "            pyplot.plot(history.history['loss'], label='train')\n",
    "            pyplot.plot(history.history['val_loss'], label='test')\n",
    "            pyplot.plot(history.history['accuracy'], label='accuracy')\n",
    "            pyplot.plot(history.history['val_accuracy'], label='test accuracy')\n",
    "            pyplot.legend()\n",
    "            pyplot.savefig(folder+'/'+file + '.png')\n",
    "\n",
    "            pickle.dump(history, open(folder+'/'+file+'-hist.p', \"wb\"))\n",
    "            model.save(folder+'/'+file+'.h5')\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "workers=[]\n",
    "for i in range(gpus):\n",
    "    \n",
    "    workers.append(Thread(target = doWork, args=(i,)))\n",
    "for worker in workers:\n",
    "    worker.start()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Putted VP22_importPz_rerefLM_noEOGs_crop_cleanChans_rerefLM_modMarker.set False\n",
      "VP22_importPz_rerefLM_noEOGs_crop_cleanChans_rerefLM_modMarker.set (2, 1, 62, 2560) (1, 1, 62, 2560) (2, 2) (1, 2)\n",
      "Done getting data\n",
      "Compiling model\n"
     ]
    }
   ],
   "source": [
    "# s = Pool(2)\n",
    "\n",
    "# master=s.map(doWork, [(x, out) for x in range(gpus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-14-d368b5877dde>\", line 32, in doWork\n",
      "    history = model.fit(train_X, train_y, epochs=10, batch_size=2, validation_data=(test_X, test_y), verbose=0, shuffle=True)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\", line 1614, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 705, in fit_loop\n",
      "    batch_size=batch_size)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 251, in iterator_fit_loop\n",
      "    model, x, y, sample_weights=sample_weights, training=True)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 511, in _process_single_batch\n",
      "    training=training)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 90, in _model_loss\n",
      "    outs, masks = model._call_and_compute_mask(inputs, **kwargs)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 856, in _call_and_compute_mask\n",
      "    mask=masks)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/network.py\", line 1031, in _run_internal_graph\n",
      "    output_tensors = layer.call(computed_tensor, **kwargs)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py\", line 970, in call\n",
      "    outputs = gen_math_ops.mat_mul(inputs, self.kernel)\n",
      "  File \"/home/sean/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4586, in mat_mul\n",
      "    _six.raise_from(_core._status_to_exception(e.code, message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.InternalError: Blas GEMM launch failed : a.shape=(2, 1280), b.shape=(1280, 2), m=2, n=2, k=1280 [Op:MatMul]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "worker.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldTF",
   "language": "python",
   "name": "oldtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
